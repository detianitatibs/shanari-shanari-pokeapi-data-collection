{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from google.api_core.page_iterator import HTTPIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defenition Values\n",
    "BUCKET_NAME = \"shanari-datalake\"\n",
    "DATASOURCE_NAME = \"pokeapi\"\n",
    "RAW_LAYER = \"raw\"\n",
    "TRANSLATED_LAYER = \"translated\"\n",
    "TARGET_DATE = date.today()\n",
    "print(f\"The target_date is {TARGET_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictをGCSへアップロードする\n",
    "def upload_json_to_gcs(\n",
    "        bucket_name: str, \n",
    "        datasource_name: str,\n",
    "        layer_name: str,\n",
    "        target_date: date,\n",
    "        object_name: str,\n",
    "        json_object: dict\n",
    "        ) -> bool:\n",
    "    # Set date of string\n",
    "    str_year = date.strftime(target_date, \"%Y\")\n",
    "    str_month = date.strftime(target_date, \"%m\")\n",
    "    str_day = date.strftime(target_date, \"%d\")\n",
    "\n",
    "    # Prepare Client\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob_path = f\"{datasource_name}/{layer_name}/{str_year}/{str_month}/{str_day}/{object_name}.json\"\n",
    "    blob = bucket.blob(blob_path)\n",
    "\n",
    "    # dump to json file\n",
    "    json_data = json.dumps(json_object, indent=4)\n",
    "\n",
    "    # 3回までは失敗してもリトライする\n",
    "    count = 0\n",
    "    while True:\n",
    "\n",
    "        # Upload to GCS\n",
    "        try:\n",
    "            blob.upload_from_string(json_data)\n",
    "            print(f\"Success to uploaded file: {blob_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading file: {e}\")\n",
    "            if count > 2:\n",
    "                return False\n",
    "            else:\n",
    "                count = count + 1\n",
    "                # countの2乗秒待つ\n",
    "                time.sleep(count * count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameをGCSへアップロードする\n",
    "def upload_df_to_gcs(\n",
    "        bucket_name: str, \n",
    "        datasource_name: str,\n",
    "        layer_name: str,\n",
    "        target_date: date,\n",
    "        object_name: str,\n",
    "        df_object: pd.DataFrame\n",
    "        ) -> bool:\n",
    "    # Set date of string\n",
    "    str_year = date.strftime(target_date, \"%Y\")\n",
    "    str_month = date.strftime(target_date, \"%m\")\n",
    "    str_day = date.strftime(target_date, \"%d\")\n",
    "\n",
    "    # Prepare Client\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob_path = f\"{datasource_name}/{layer_name}/{str_year}/{str_month}/{str_day}/{object_name}.csv\"\n",
    "    blob = bucket.blob(blob_path)\n",
    "\n",
    "    # dump to csv file\n",
    "    csv_data = df_object.to_csv(index=False)\n",
    "\n",
    "    # 3回までは失敗してもリトライする\n",
    "    count = 0\n",
    "    while True:\n",
    "\n",
    "        # Upload to GCS\n",
    "        try:\n",
    "            blob.upload_from_string(csv_data)\n",
    "            print(f\"Success to uploaded file: {blob_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading file: {e}\")\n",
    "            if count > 2:\n",
    "                return False\n",
    "            else:\n",
    "                count = count + 1\n",
    "                # countの2乗秒待つ\n",
    "                time.sleep(count * count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_data(url: str) -> dict:\n",
    "    # RestAPIをコールして値を取得する共通処理\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != requests.codes.ok:\n",
    "        HTTPError(f\"Extract Error, URL: {url}\")\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pokemon\n",
    "\n",
    "# 全体のリストを取得する\n",
    "pokemon_list = extract_json_data(url=\"https://pokeapi.co/api/v2/pokemon/?offset=0&limit=10000\")\n",
    "\n",
    "# ポケモン毎にJSONを取得してGCSへアップロードする\n",
    "for p in pokemon_list[\"results\"]:\n",
    "    pokemon = extract_json_data(url=p[\"url\"])\n",
    "    is_uploaded = upload_json_to_gcs(\n",
    "        bucket_name=BUCKET_NAME,\n",
    "        datasource_name=DATASOURCE_NAME,\n",
    "        layer_name=RAW_LAYER,\n",
    "        target_date=TARGET_DATE,\n",
    "        object_name=\"pokemon_\"+p[\"url\"].split(\"/\")[-2], # \"pokemon_<id>.json\"になる\n",
    "        json_object=pokemon\n",
    "    )\n",
    "\n",
    "    if not is_uploaded:\n",
    "        break;\n",
    "\n",
    "    # 0.5秒待つ\n",
    "    time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ability\n",
    "\n",
    "# 全体のリストを取得する\n",
    "ability_list = extract_json_data(url=\"https://pokeapi.co/api/v2/ability/?offset=0&limit=10000\")\n",
    "\n",
    "# 特性毎にJSONを取得してGCSへアップロードする\n",
    "for i in ability_list[\"results\"]:\n",
    "    ability = extract_json_data(url=i[\"url\"])\n",
    "    is_uploaded = upload_json_to_gcs(\n",
    "        bucket_name=BUCKET_NAME,\n",
    "        datasource_name=DATASOURCE_NAME,\n",
    "        layer_name=RAW_LAYER,\n",
    "        target_date=TARGET_DATE,\n",
    "        object_name=\"ability_\"+i[\"url\"].split(\"/\")[-2], # \"ability_<id>.json\"になる\n",
    "        json_object=ability\n",
    "    )\n",
    "\n",
    "    if not is_uploaded:\n",
    "        break;\n",
    "\n",
    "    # 0.5秒待つ\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nature\n",
    "\n",
    "# 全体のリストを取得する\n",
    "nature_list = extract_json_data(url=\"https://pokeapi.co/api/v2/nature/?offset=0&limit=10000\")\n",
    "\n",
    "# 性格毎にJSONを取得してGCSへアップロードする\n",
    "for i in nature_list[\"results\"]:\n",
    "    nature = extract_json_data(url=i[\"url\"])\n",
    "    is_uploaded = upload_json_to_gcs(\n",
    "        bucket_name=BUCKET_NAME,\n",
    "        datasource_name=DATASOURCE_NAME,\n",
    "        layer_name=RAW_LAYER,\n",
    "        target_date=TARGET_DATE,\n",
    "        object_name=\"nature_\"+i[\"url\"].split(\"/\")[-2], # \"nature_<id>.json\"になる\n",
    "        json_object=nature\n",
    "    )\n",
    "\n",
    "    if not is_uploaded:\n",
    "        break;\n",
    "\n",
    "    # 0.5秒待つ\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pokemon Form\n",
    "\n",
    "# 全体のリストを取得する\n",
    "pokemon_form_list = extract_json_data(url=\"https://pokeapi.co/api/v2/pokemon-form/?offset=0&limit=10000\")\n",
    "\n",
    "# フォーム毎にJSONを取得してGCSへアップロードする\n",
    "for i in pokemon_form_list[\"results\"]:\n",
    "    pokemon_form = extract_json_data(url=i[\"url\"])\n",
    "    is_uploaded = upload_json_to_gcs(\n",
    "        bucket_name=BUCKET_NAME,\n",
    "        datasource_name=DATASOURCE_NAME,\n",
    "        layer_name=RAW_LAYER,\n",
    "        target_date=TARGET_DATE,\n",
    "        object_name=\"pokemon-form_\"+i[\"url\"].split(\"/\")[-2], # \"pokemon-form_<id>.json\"になる\n",
    "        json_object=pokemon_form\n",
    "    )\n",
    "\n",
    "    if not is_uploaded:\n",
    "        break;\n",
    "\n",
    "    # 0.5秒待つ\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pokemon Species\n",
    "\n",
    "# 全体のリストを取得する\n",
    "pokemon_species_list = extract_json_data(url=\"https://pokeapi.co/api/v2/pokemon-species/?offset=0&limit=10000\")\n",
    "\n",
    "# フォーム毎にJSONを取得してGCSへアップロードする\n",
    "for i in pokemon_species_list[\"results\"]:\n",
    "    pokemon_species = extract_json_data(url=i[\"url\"])\n",
    "    is_uploaded = upload_json_to_gcs(\n",
    "        bucket_name=BUCKET_NAME,\n",
    "        datasource_name=DATASOURCE_NAME,\n",
    "        layer_name=RAW_LAYER,\n",
    "        target_date=TARGET_DATE,\n",
    "        object_name=\"pokemon-species_\"+i[\"url\"].split(\"/\")[-2], # \"pokemon-species_<id>.json\"になる\n",
    "        json_object=pokemon_species\n",
    "    )\n",
    "\n",
    "    if not is_uploaded:\n",
    "        break;\n",
    "\n",
    "    # 0.5秒待つ\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moves\n",
    "\n",
    "# 全体のリストを取得する\n",
    "move_list = extract_json_data(url=\"https://pokeapi.co/api/v2/move/?offset=0&limit=10000\")\n",
    "\n",
    "# フォーム毎にJSONを取得してGCSへアップロードする\n",
    "for i in move_list[\"results\"]:\n",
    "    move = extract_json_data(url=i[\"url\"])\n",
    "    is_uploaded = upload_json_to_gcs(\n",
    "        bucket_name=BUCKET_NAME,\n",
    "        datasource_name=DATASOURCE_NAME,\n",
    "        layer_name=RAW_LAYER,\n",
    "        target_date=TARGET_DATE,\n",
    "        object_name=\"move_\"+i[\"url\"].split(\"/\")[-2], # \"move_<id>.json\"になる\n",
    "        json_object=move\n",
    "    )\n",
    "\n",
    "    if not is_uploaded:\n",
    "        break;\n",
    "\n",
    "    # 0.5秒待つ\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(\n",
    "        bucket_name: str, \n",
    "        datasource_name: str,\n",
    "        layer_name: str,\n",
    "        target_date: date,\n",
    "        object_name: str,\n",
    "        ) -> list[HTTPIterator]:\n",
    "    # Set date of string\n",
    "    str_year = date.strftime(target_date, \"%Y\")\n",
    "    str_month = date.strftime(target_date, \"%m\")\n",
    "    str_day = date.strftime(target_date, \"%d\")\n",
    "    prefix = f\"{datasource_name}/{layer_name}/{str_year}/{str_month}/{str_day}/{object_name}_\"\n",
    "\n",
    "    # GCSのファイル一覧を取得する共通処理\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "    \n",
    "    return blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_from_gcs(\n",
    "        bucket_name: str,\n",
    "        prefix: str\n",
    ") -> dict:\n",
    "    # GCSにあるjsonファイルを取得する共通処理\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(prefix)\n",
    "\n",
    "    # 3回までは失敗してもリトライする\n",
    "    count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            with blob.open('rb') as f:\n",
    "                data = json.load(f)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {e}\")\n",
    "            if count > 2:\n",
    "                return {}\n",
    "            else:\n",
    "                count = count + 1\n",
    "                # countの2乗秒待つ\n",
    "                time.sleep(count * count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pokemon\n",
    "pokemon_blobs = get_file_path(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=RAW_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"pokemon\"\n",
    "    )\n",
    "\n",
    "str_year = date.strftime(TARGET_DATE, \"%Y\")\n",
    "str_month = date.strftime(TARGET_DATE, \"%m\")\n",
    "str_day = date.strftime(TARGET_DATE, \"%d\")\n",
    "\n",
    "dfs_pokemon = []\n",
    "dfs_pokemon_moves = []\n",
    "dfs_pokemon_sprites = []\n",
    "for blob in pokemon_blobs:\n",
    "    print(f\"Name of Blob: {blob.name}\")\n",
    "    pokemon_data = read_json_from_gcs(bucket_name=BUCKET_NAME, prefix=blob.name)\n",
    "\n",
    "    species_id = pokemon_data[\"species\"][\"url\"].split(\"/\")[-2]\n",
    "    species_prefix = f\"{DATASOURCE_NAME}/{RAW_LAYER}/{str_year}/{str_month}/{str_day}/pokemon-species_{species_id}.json\"\n",
    "    species_data = read_json_from_gcs(bucket_name=BUCKET_NAME, prefix=species_prefix)\n",
    "\n",
    "    # DataFrame of Pokemon (Master)\n",
    "    type_2 = None\n",
    "    if len(pokemon_data[\"types\"]) > 1:\n",
    "        type_2 = [type[\"type\"][\"name\"] for type in pokemon_data[\"types\"] if type[\"slot\"] == 2][0]\n",
    "    pokemon_name_jp = None\n",
    "    if len(species_data) > 0:\n",
    "        pokemon_name_jp = [name[\"name\"] for name in species_data[\"names\"] if name[\"language\"][\"name\"] == \"ja\"][0]\n",
    "    dfs_pokemon.append(\n",
    "        pd.DataFrame({\n",
    "            \"pokemon_id\": [pokemon_data[\"id\"]],\n",
    "            \"pokemon_name_en\": [pokemon_data[\"name\"]],\n",
    "            \"pokemon_name_jp\": [pokemon_name_jp],\n",
    "            \"height\": [pokemon_data[\"height\"]],\n",
    "            \"weight\": [pokemon_data[\"weight\"]],\n",
    "            \"type_1\": [[type[\"type\"][\"name\"] for type in pokemon_data[\"types\"] if type[\"slot\"] == 1][0]],\n",
    "            \"type_2\": [type_2],\n",
    "            \"stat_hp\": [[stat[\"base_stat\"] for stat in pokemon_data[\"stats\"] if stat[\"stat\"][\"name\"] == \"hp\"][0]],\n",
    "            \"stat_attack\": [[stat[\"base_stat\"] for stat in pokemon_data[\"stats\"] if stat[\"stat\"][\"name\"] == \"attack\"][0]],\n",
    "            \"stat_defense\": [[stat[\"base_stat\"] for stat in pokemon_data[\"stats\"] if stat[\"stat\"][\"name\"] == \"defense\"][0]],\n",
    "            \"stat_special_attack\": [[stat[\"base_stat\"] for stat in pokemon_data[\"stats\"] if stat[\"stat\"][\"name\"] == \"special-attack\"][0]],\n",
    "            \"stat_special_defense\": [[stat[\"base_stat\"] for stat in pokemon_data[\"stats\"] if stat[\"stat\"][\"name\"] == \"special-defense\"][0]],\n",
    "            \"stat_speed\": [[stat[\"base_stat\"] for stat in pokemon_data[\"stats\"] if stat[\"stat\"][\"name\"] == \"speed\"][0]],\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # DataFrame of Pokemon - Moves (1:N)\n",
    "    if len(pokemon_data[\"moves\"]) != 0:\n",
    "        dfs_version_group_detail = []\n",
    "        for pokemon_move in pokemon_data[\"moves\"]:\n",
    "            for version_group_detail in pokemon_move[\"version_group_details\"]:\n",
    "                dfs_version_group_detail.append(\n",
    "                        pd.DataFrame({\n",
    "                        \"pokemon_id\": [pokemon_data[\"id\"]],\n",
    "                        \"move_name\": [pokemon_move[\"move\"][\"name\"]],\n",
    "                        \"move_learn_method\": [version_group_detail[\"move_learn_method\"][\"name\"]],\n",
    "                        \"level_learned_at\": [version_group_detail[\"level_learned_at\"]],\n",
    "                        \"version_group\": [version_group_detail[\"version_group\"][\"name\"]]  \n",
    "                }))\n",
    "        dfs_pokemon_moves.append(pd.concat(dfs_version_group_detail))\n",
    "\n",
    "    # DataFrame of Pokemon - Sprites (1:N)\n",
    "    dfs_pokemon_sprites.append(\n",
    "        pd.DataFrame({\n",
    "            \"pokemon_id\": [pokemon_data[\"id\"]],\n",
    "            \"front_default_url\": [pokemon_data[\"sprites\"][\"front_default\"]],\n",
    "            \"front_female_url\": [pokemon_data[\"sprites\"][\"front_female\"]],\n",
    "            \"front_shiny_url\": [pokemon_data[\"sprites\"][\"front_shiny\"]],\n",
    "            \"front_shiny_female_url\": [pokemon_data[\"sprites\"][\"front_shiny_female\"]],\n",
    "            \"back_default_url\": [pokemon_data[\"sprites\"][\"back_default\"]],\n",
    "            \"back_female_url\": [pokemon_data[\"sprites\"][\"back_female\"]],\n",
    "            \"back_shiny_url\": [pokemon_data[\"sprites\"][\"back_shiny\"]],\n",
    "            \"back_shiny_female_url\": [pokemon_data[\"sprites\"][\"back_shiny_female\"]],\n",
    "        })\n",
    "    )\n",
    "\n",
    "df_pokemon = pd.concat(dfs_pokemon)\n",
    "df_pokemon_moves = pd.concat(dfs_pokemon_moves)\n",
    "df_pokemon_sprites = pd.concat(dfs_pokemon_sprites)\n",
    "\n",
    "upload_df_to_gcs(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=TRANSLATED_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"pokemon\",\n",
    "    df_object=df_pokemon\n",
    ")\n",
    "upload_df_to_gcs(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=TRANSLATED_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"pokemon_moves\",\n",
    "    df_object=df_pokemon_moves\n",
    ")\n",
    "upload_df_to_gcs(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=TRANSLATED_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"pokemon_sprites\",\n",
    "    df_object=df_pokemon_sprites\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ability\n",
    "ability_blobs = get_file_path(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=RAW_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"ability\"\n",
    "    )\n",
    "\n",
    "dfs_ability = []\n",
    "for blob in ability_blobs:\n",
    "    print(f\"Name of Blob: {blob.name}\")\n",
    "    ability_data = read_json_from_gcs(bucket_name=BUCKET_NAME, prefix=blob.name)\n",
    "    abitily_name_jp = None\n",
    "    if len(ability_data[\"names\"]) > 1:\n",
    "        abitily_name_jp = [ language  for language in ability_data[\"names\"] if language[\"language\"][\"name\"] == \"ja-Hrkt\" ][0][\"name\"]\n",
    "    dfs_ability.append(\n",
    "        pd.DataFrame({\n",
    "            \"ability_id\": [ability_data[\"id\"]],\n",
    "            \"ability_name_en\": [ability_data[\"name\"]],\n",
    "            \"ability_name_jp\": [abitily_name_jp],\n",
    "        })\n",
    "    )\n",
    "df_ability = pd.concat(dfs_ability)\n",
    "\n",
    "upload_df_to_gcs(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=TRANSLATED_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"ability\",\n",
    "    df_object=df_ability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nature\n",
    "nature_blobs = get_file_path(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=RAW_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"nature\"\n",
    ")\n",
    "dfs_nature = []\n",
    "for blob in nature_blobs:\n",
    "    print(f\"Name of Blob: {blob.name}\")\n",
    "    nature_data = read_json_from_gcs(bucket_name=BUCKET_NAME, prefix=blob.name)\n",
    "\n",
    "    nature_name_jp = None\n",
    "    if len(nature_data[\"names\"]) > 1:\n",
    "        nature_name_jp = [ language  for language in nature_data[\"names\"] if language[\"language\"][\"name\"] == \"ja-Hrkt\" ][0][\"name\"]\n",
    "    \n",
    "    increased_stat = None\n",
    "    if nature_data[\"increased_stat\"] is not None:\n",
    "        increased_stat = nature_data[\"increased_stat\"][\"name\"]\n",
    "    \n",
    "    decreased_stat = None\n",
    "    if nature_data[\"decreased_stat\"] is not None:\n",
    "        decreased_stat = nature_data[\"decreased_stat\"][\"name\"]\n",
    "    dfs_nature.append(\n",
    "        pd.DataFrame({\n",
    "            \"nature_id\": [nature_data[\"id\"]],\n",
    "            \"nature_name_en\": [nature_data[\"name\"]],\n",
    "            \"nature_name_jp\": [nature_name_jp],\n",
    "            \"increased_stat\": [increased_stat],\n",
    "            \"decreased_stat\": [decreased_stat],\n",
    "        })\n",
    "    )\n",
    "\n",
    "df_nature = pd.concat(dfs_nature)\n",
    "\n",
    "upload_df_to_gcs(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=TRANSLATED_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"nature\",\n",
    "    df_object=df_nature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pokemon Form\n",
    "form_blobs = get_file_path(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=RAW_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"pokemon-form\"\n",
    ")\n",
    "dfs_form = []\n",
    "for blob in form_blobs:\n",
    "    print(f\"Name of Blob: {blob.name}\")\n",
    "    form_data = read_json_from_gcs(bucket_name=BUCKET_NAME, prefix=blob.name)\n",
    "    if form_data[\"form_name\"] != \"\":\n",
    "        form_name_jp = None\n",
    "        if len(form_data[\"form_names\"]) > 1:\n",
    "            form_name_lang = [ language  for language in form_data[\"form_names\"] if language[\"language\"][\"name\"] == \"ja-Hrkt\" ]\n",
    "            form_name_jp = form_name_lang[0][\"name\"] if len(form_name_lang) > 0 else None\n",
    "        dfs_form.append(\n",
    "            pd.DataFrame({\n",
    "                \"form_id\": [form_data[\"id\"]],\n",
    "                \"form_name_en\": [form_data[\"name\"]],\n",
    "                \"form_name_jp\": [form_name_jp]\n",
    "            })\n",
    "        )\n",
    "\n",
    "df_form = pd.concat(dfs_form)\n",
    "\n",
    "upload_df_to_gcs(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=TRANSLATED_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"pokemon-form\",\n",
    "    df_object=df_form\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moves\n",
    "move_blobs = get_file_path(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=RAW_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"move\"\n",
    ")\n",
    "\n",
    "dfs_moves = []\n",
    "dfs_move_stat_change = []\n",
    "for blob in move_blobs:\n",
    "    print(f\"Name of Blob: {blob.name}\")\n",
    "    move_data = read_json_from_gcs(bucket_name=BUCKET_NAME,prefix=blob.name)\n",
    "\n",
    "    move_name_jp = None\n",
    "    if len(move_data[\"names\"]) > 1:\n",
    "        move_name_lang = [ language  for language in move_data[\"names\"] if language[\"language\"][\"name\"] == \"ja-Hrkt\" ]\n",
    "        move_name_jp = move_name_lang[0][\"name\"] if len(move_name_lang) > 0 else None\n",
    "    \n",
    "    effect_entries = None\n",
    "    if len(move_data[\"effect_entries\"]) > 0:\n",
    "        effect_entries = move_data[\"effect_entries\"][0][\"effect\"]\n",
    "\n",
    "    if move_data[\"meta\"] is None:\n",
    "        ailment = None\n",
    "        move_category = None\n",
    "        crit_rate = None\n",
    "        drain = None\n",
    "        flinch_chance = None\n",
    "        healing = None\n",
    "        max_hits = None\n",
    "        min_hits = None\n",
    "        max_turns = None\n",
    "        min_turns = None\n",
    "        stat_chance = None\n",
    "    else:\n",
    "        ailment = move_data[\"meta\"][\"ailment\"][\"name\"]\n",
    "        move_category = move_data[\"meta\"][\"category\"][\"name\"]\n",
    "        crit_rate = move_data[\"meta\"][\"crit_rate\"]\n",
    "        drain = move_data[\"meta\"][\"drain\"]\n",
    "        flinch_chance = move_data[\"meta\"][\"flinch_chance\"]\n",
    "        healing = move_data[\"meta\"][\"healing\"]\n",
    "        max_hits = move_data[\"meta\"][\"max_hits\"]\n",
    "        min_hits = move_data[\"meta\"][\"min_hits\"]\n",
    "        max_turns = move_data[\"meta\"][\"max_turns\"]\n",
    "        min_turns = move_data[\"meta\"][\"min_turns\"]\n",
    "        stat_chance = move_data[\"meta\"][\"stat_chance\"]\n",
    "    dfs_moves.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"move_id\": [move_data[\"id\"]],\n",
    "                \"move_name_en\": [move_data[\"name\"]],\n",
    "                \"move_name_jp\": [move_name_jp],\n",
    "                \"type\": [move_data[\"type\"][\"name\"]],\n",
    "                \"power\": [move_data[\"power\"]],\n",
    "                \"pp\": [move_data[\"pp\"]],\n",
    "                \"priority\": [move_data[\"priority\"]],\n",
    "                \"accuracy\": [move_data[\"accuracy\"]],\n",
    "                \"damage_class\": [move_data[\"damage_class\"][\"name\"]],\n",
    "                \"effect_chance\": [move_data[\"effect_chance\"]],\n",
    "                \"effect_entries\": [effect_entries],\n",
    "                \"ailment\": [ailment],\n",
    "                \"move_category\": [move_category],\n",
    "                \"crit_rate\": [crit_rate],\n",
    "                \"drain\": [drain],\n",
    "                \"flinch_chance\": [flinch_chance],\n",
    "                \"healing\": [healing],\n",
    "                \"max_hits\": [max_hits],\n",
    "                \"min_hits\": [min_hits],\n",
    "                \"max_turns\": [max_turns],\n",
    "                \"min_turns\": [min_turns],\n",
    "                \"stat_chance\": [stat_chance],\n",
    "                \"target\": [move_data[\"target\"][\"name\"]]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if len(move_data[\"stat_changes\"]) > 0:\n",
    "        dfs_stats = []\n",
    "        for stat in move_data[\"stat_changes\"]:\n",
    "            dfs_stats.append(\n",
    "                pd.DataFrame({\n",
    "                    \"move_id\": [move_data[\"id\"]],\n",
    "                    \"stat_change_num\": [stat[\"change\"]],\n",
    "                    \"stat_change_name\": [stat[\"stat\"][\"name\"]]\n",
    "                })\n",
    "            )\n",
    "        dfs_move_stat_change.append(pd.concat(dfs_stats))\n",
    "\n",
    "df_moves = pd.concat(dfs_moves)\n",
    "df_move_stat_change = pd.concat(dfs_move_stat_change)\n",
    "\n",
    "upload_df_to_gcs(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=TRANSLATED_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"moves\",\n",
    "    df_object=df_moves\n",
    ")\n",
    "upload_df_to_gcs(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    datasource_name=DATASOURCE_NAME,\n",
    "    layer_name=TRANSLATED_LAYER,\n",
    "    target_date=TARGET_DATE,\n",
    "    object_name=\"move_stat_change\",\n",
    "    df_object=df_move_stat_change\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook-FdyUTCTB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
